{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "from typing import Any, Type, List, Optional, Callable, Tuple\n",
    "from functools import partial\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from cjm_yolox_pytorch.model import build_model, NORM_STATS\n",
    "from cjm_yolox_pytorch.utils import generate_output_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class YOLOXInferenceWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a wrapper for the YOLOX <https://arxiv.org/abs/2107.08430> object detection model.\n",
    "    The class handles preprocessing of the input, postprocessing of the model output, and calculation of bounding boxes and their probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 model:nn.Module, # The YOLOX model.\n",
    "                 normalize_mean:torch.Tensor=torch.tensor([[[0.]]]*3)[None], # The mean values for normalization.\n",
    "                 normalize_std:torch.Tensor=torch.tensor([[[1.]]]*3)[None], # The standard deviation values for normalization.\n",
    "                 strides:Optional[List[int]]=[8, 16, 32], # The strides for the model.\n",
    "                 scale_inp:bool=False, # Whether to scale the input by dividing by 255.\n",
    "                 channels_last:bool=False, # Whether the input tensor has channels first.\n",
    "                 run_box_and_prob_calculation:bool=True # Whether to calculate the bounding boxes and their probabilities.\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Constructor for the YOLOXInferenceWrapper class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.register_buffer(\"normalize_mean\", normalize_mean)\n",
    "        self.register_buffer(\"normalize_std\", normalize_std)\n",
    "        self.scale_inp = scale_inp\n",
    "        self.channels_last = channels_last\n",
    "        self.register_buffer(\"strides\", torch.tensor(strides))\n",
    "        self.run_box_and_prob_calculation = run_box_and_prob_calculation\n",
    "        self.input_dim_slice = slice(1, 3) if self.channels_last else slice(2, 4)\n",
    "\n",
    "    def preprocess_input(self, x):\n",
    "        \"\"\"\n",
    "        Preprocess the input for the model.\n",
    "\n",
    "        Parameters:\n",
    "        x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: The preprocessed input tensor.\n",
    "        \"\"\"\n",
    "        # Scale the input if required\n",
    "        if self.scale_inp:\n",
    "            x = x / 255.0\n",
    "\n",
    "        # Permute the dimensions of the input to bring the channels to the front if required\n",
    "        if self.channels_last:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Normalize the input\n",
    "        x = (x - self.normalize_mean) / self.normalize_std\n",
    "        return x\n",
    "        \n",
    "    def process_output(self, model_output):\n",
    "        \"\"\"\n",
    "        Postprocess the output of the model.\n",
    "\n",
    "        Parameters:\n",
    "        model_output (tuple): The output of the model.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: The postprocessed output tensor.\n",
    "        \"\"\"\n",
    "        cls_scores, bbox_preds, objectness = model_output\n",
    "        \n",
    "        stride_flats = []\n",
    "        # Iterate over the output strides\n",
    "        for i in range(self.strides.shape[0]):\n",
    "            cls = torch.sigmoid(cls_scores[i])  # Apply sigmoid to the class scores\n",
    "            bbox = bbox_preds[i]  # Get the bounding box predictions\n",
    "            obj = torch.sigmoid(objectness[i])  # Apply sigmoid to the objectness scores\n",
    "            cat = torch.cat((bbox, obj, cls), dim=1)  # Concatenate the bounding boxes, objectness, and class scores\n",
    "            flat = torch.flatten(cat, start_dim=2)  # Flatten the tensor from the second dimension\n",
    "            stride_flats.append(flat)\n",
    "\n",
    "        # Concatenate all the flattened tensors\n",
    "        full_cat = torch.cat(stride_flats, dim=2)\n",
    "        full_cat_out = full_cat.permute(0, 2, 1)  # Permute the dimensions of the tensor\n",
    "        return full_cat_out\n",
    "\n",
    "    def calculate_boxes_and_probs(self, model_output, output_grids):\n",
    "        \"\"\"\n",
    "        Calculate the bounding boxes and their probabilities.\n",
    "\n",
    "        Parameters:\n",
    "        model_output (torch.Tensor): The output of the model.\n",
    "        output_grids (torch.Tensor): The output grids.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: The tensor containing the bounding box coordinates, class labels, and maximum probabilities.\n",
    "        \"\"\"\n",
    "        # Calculate the bounding box coordinates\n",
    "        box_centroids = (model_output[..., :2] + output_grids[..., :2]) * output_grids[..., 2:]\n",
    "        box_sizes = torch.exp(model_output[..., 2:4]) * output_grids[..., 2:]\n",
    "        \n",
    "        x0, y0 = [t.squeeze(dim=2) for t in torch.split(box_centroids - box_sizes / 2, 1, dim=2)]\n",
    "        w, h = [t.squeeze(dim=2) for t in torch.split(box_sizes, 1, dim=2)]\n",
    "\n",
    "        # Calculate the probabilities for each class\n",
    "        box_objectness = model_output[..., 4]\n",
    "        box_cls_scores = model_output[..., 5:]\n",
    "        box_probs = box_objectness.unsqueeze(-1) * box_cls_scores\n",
    "\n",
    "        # Get the maximum probability and corresponding class for each proposal\n",
    "        max_probs, labels = torch.max(box_probs, dim=-1)\n",
    "\n",
    "        return torch.stack([x0, y0, w, h, labels.float(), max_probs], dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The forward method for the YOLOXInferenceWrapper class.\n",
    "\n",
    "        Parameters:\n",
    "        x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: The output tensor.\n",
    "        \"\"\"\n",
    "        \n",
    "        input_dims = x.shape[self.input_dim_slice]\n",
    "                \n",
    "        # Preprocess the input\n",
    "        x = self.preprocess_input(x)\n",
    "        # Pass the input through the model\n",
    "        x = self.model(x)\n",
    "        # Postprocess the model output\n",
    "        x = self.process_output(x)\n",
    "        \n",
    "        if self.run_box_and_prob_calculation:\n",
    "            # Generate output grids\n",
    "            output_grids = generate_output_grids(*input_dims, self.strides).to(x.device)\n",
    "            # Calculate the bounding boxes and their probabilities\n",
    "            x = self.calculate_boxes_and_probs(x, output_grids)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file ./pretrained_checkpoints/yolox_tiny.pth already exists and overwrite is set to False.\n",
      "cls_scores: [torch.Size([1, 19, 32, 32]), torch.Size([1, 19, 16, 16]), torch.Size([1, 19, 8, 8])]\n",
      "bbox_preds: [torch.Size([1, 4, 32, 32]), torch.Size([1, 4, 16, 16]), torch.Size([1, 4, 8, 8])]\n",
      "objectness: [torch.Size([1, 1, 32, 32]), torch.Size([1, 1, 16, 16]), torch.Size([1, 1, 8, 8])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/980_1TB_1/Projects/GitHub/cjm-yolox-pytorch/cjm_yolox_pytorch/model.py:792: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(checkpoint_path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "model_type = 'yolox_tiny'\n",
    "\n",
    "model = build_model(model_type, 19, pretrained=True)\n",
    "\n",
    "test_inp = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "with torch.no_grad():\n",
    "    cls_scores, bbox_preds, objectness = model(test_inp)\n",
    "    \n",
    "print(f\"cls_scores: {[cls_score.shape for cls_score in cls_scores]}\")\n",
    "print(f\"bbox_preds: {[bbox_pred.shape for bbox_pred in bbox_preds]}\")\n",
    "print(f\"objectness: {[objectness.shape for objectness in objectness]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1344, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_stats = [*NORM_STATS[model_type].values()]\n",
    "\n",
    "# Convert the normalization stats to tensors\n",
    "mean_tensor = torch.tensor(norm_stats[0]).view(1, 3, 1, 1)\n",
    "std_tensor = torch.tensor(norm_stats[1]).view(1, 3, 1, 1)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval();\n",
    "\n",
    "# Wrap the model with preprocessing and post-processing steps\n",
    "wrapped_model = YOLOXInferenceWrapper(model, \n",
    "                                      mean_tensor, \n",
    "                                      std_tensor, \n",
    "                                      scale_inp=False, \n",
    "                                      channels_last=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_output = wrapped_model(test_inp)\n",
    "model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
