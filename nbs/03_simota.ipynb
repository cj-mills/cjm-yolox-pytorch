{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simota\n",
    "\n",
    "> An implementation of SimOTA label assignment for the [YOLOX](https://arxiv.org/abs/2107.08430) object detection model based on [OpenMMLab](https://github.com/open-mmlab)â€™s implementation in the [mmdetection](https://github.com/open-mmlab/mmdetection) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp simota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Type, List, Optional, Callable, Tuple, Union\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class AssignResult:\n",
    "    \"\"\"\n",
    "    Stores assignments between predicted bounding boxes and actual truth bounding boxes.\n",
    "    \n",
    "    Based on OpenMMLab's implementation in the mmdetection library:\n",
    "    \n",
    "    - [OpenMMLab's Implementation](https://github.com/open-mmlab/mmdetection/blob/d64e719172335fa3d7a757a2a3636bd19e9efb62/mmdet/core/bbox/assigners/assign_result.py#L7)\n",
    "\n",
    "    \"\"\"\n",
    "    num_ground_truth_boxes: int # The number of actual truth boxes considered when computing this assignment\n",
    "    ground_truth_box_indices: torch.LongTensor # For each predicted bounding box, this indicates the 1-based index of the assigned actual truth box. 0 means unassigned and -1 means ignore.\n",
    "    max_iou_values: torch.FloatTensor # The Intersection over Union (IoU) between the predicted bounding box and its assigned actual truth box.\n",
    "    category_labels: torch.LongTensor = field(default=None) # If specified, for each predicted bounding box, this indicates the category label of the assigned actual truth box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimOTAAssigner():\n",
    "    \"\"\"\n",
    "    The `SimOTAAssigner` class assigns predicted bounding boxes to their corresponding ground truth boxes in object detection tasks. \n",
    "    It uses a process called SimOTA that formulates the assignment task as an optimal transport problem via a dynamic top-k strategy.\n",
    "    \n",
    "    It calculates a cost matrix based on classification and regression (Intersection over Union, IoU) costs. \n",
    "    It then uses this cost matrix to dynamically assign each ground truth object to the best matching bounding box predictions while resolving conflicts to ensure each prediction pairs with a single ground truth.\n",
    "    \n",
    "    Based on OpenMMLab's implementation in the mmdetection library:\n",
    "    \n",
    "    - [OpenMMLab's Implementation](https://github.com/open-mmlab/mmdetection/blob/d64e719172335fa3d7a757a2a3636bd19e9efb62/mmdet/core/bbox/assigners/sim_ota_assigner.py#L14)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 center_radius:float=2.5, # Ground truth center size to judge whether a output_grid_box is in center.\n",
    "                 candidate_topk:int=10, # The candidate top-k which used to get top-k ious to calculate dynamic-k.\n",
    "                 iou_weight:float=3.0, # The scale factor for regression iou cost.\n",
    "                 cls_weight:float=1.0 # The scale factor for classification cost.\n",
    "                ):\n",
    "        self.center_radius = center_radius\n",
    "        self.candidate_topk = candidate_topk\n",
    "        self.iou_weight = iou_weight\n",
    "        self.cls_weight = cls_weight\n",
    "\n",
    "    def assign(self,\n",
    "               pred_scores:torch.Tensor, # Classification scores of each output grid box across all classes.\n",
    "               output_grid_boxes:torch.Tensor, # Output grid bounding boxes of one image in format [cx, xy, stride_w, stride_y].\n",
    "               decoded_bboxes:torch.Tensor, # Predicted bounding boxes of one image in format [tl_x, tl_y, br_x, br_y].\n",
    "               gt_bboxes:torch.Tensor, # Ground truth bounding boxes of one image in format [tl_x, tl_y, br_x, br_y].\n",
    "               gt_labels:torch.Tensor, # Ground truth labels of one image, It is a Tensor with shape [num_gts].\n",
    "               gt_bboxes_ignore:Optional[torch.Tensor]=None, # Ground truth bounding boxes that are labelled as `ignored`, e.g., crowd boxes in COCO.\n",
    "               eps:float=1e-7 # A value added to the denominator for numerical stability.\n",
    "              ):\n",
    "        \"\"\"Assign ground truth to output_grid_boxes using SimOTA.\n",
    "\n",
    "        This method assigns predicted bounding boxes to ground truth boxes based on the computed cost matrix. \n",
    "        It first extracts valid box predictions and scores. \n",
    "        It then calculates the total cost matrix using IoU and classification costs. \n",
    "        Finally, it uses the cost matrix to assign each prediction to a ground truth box.\n",
    "        \"\"\"\n",
    "        HIGH_COST_VALUE = 100000000\n",
    "        num_gt = gt_bboxes.size(0)\n",
    "        num_bboxes = decoded_bboxes.size(0)\n",
    "\n",
    "        # assign 0 by default\n",
    "        assigned_gt_inds = decoded_bboxes.new_full((num_bboxes, ), 0, dtype=torch.long)\n",
    "        if num_gt == 0 or num_bboxes == 0:\n",
    "            # No ground truth or boxes, return empty assignment\n",
    "            max_overlaps = decoded_bboxes.new_zeros((num_bboxes, ))\n",
    "            if num_gt == 0:\n",
    "                # No truth, assign everything to background\n",
    "                assigned_gt_inds[:] = 0\n",
    "            if gt_labels is None:\n",
    "                assigned_labels = None\n",
    "            else:\n",
    "                assigned_labels = decoded_bboxes.new_full((num_bboxes, ), -1, dtype=torch.long)\n",
    "            return AssignResult(num_gt, assigned_gt_inds, max_overlaps, category_labels=assigned_labels)\n",
    "        \n",
    "        # Get info whether a output_grid_box is in gt bounding box and also the center of gt bounding box\n",
    "        valid_mask, is_in_boxes_and_center = self.get_in_gt_and_in_center_info(output_grid_boxes, gt_bboxes)\n",
    "        \n",
    "        # Extract valid bounding boxes and scores (i.e., those in ground truth boxes and centers)\n",
    "        valid_decoded_bbox = decoded_bboxes[valid_mask]\n",
    "        valid_pred_scores = pred_scores[valid_mask]\n",
    "        num_valid = valid_decoded_bbox.size(0)\n",
    "\n",
    "        # Compute IoU between valid decoded bounding boxes and gt bounding boxes\n",
    "        pairwise_ious = torchvision.ops.generalized_box_iou(valid_decoded_bbox, gt_bboxes)\n",
    "            \n",
    "        # Compute IoU cost\n",
    "        iou_cost = -torch.log(pairwise_ious + eps)\n",
    "                \n",
    "        # Convert gt_labels to one-hot format and calculate classification cost\n",
    "        gt_onehot_label = F.one_hot(gt_labels.to(torch.int64), pred_scores.shape[-1]).float().unsqueeze(0).repeat(num_valid, 1, 1)\n",
    "        valid_pred_scores = valid_pred_scores.unsqueeze(1).repeat(1, num_gt, 1)\n",
    "        \n",
    "        cls_cost = F.binary_cross_entropy_with_logits(valid_pred_scores, gt_onehot_label, reduction='none').sum(-1)\n",
    "        \n",
    "        # Calculate total cost matrix by combining classification and IoU costs, \n",
    "        # and assign a high cost (HIGH_COST_VALUE) for bboxes not in both boxes and centers\n",
    "        cost_matrix = cls_cost * self.cls_weight + iou_cost * self.iou_weight + (~is_in_boxes_and_center) * HIGH_COST_VALUE\n",
    "\n",
    "        # Perform matching between ground truth and valid bounding boxes based on the cost matrix\n",
    "        matched_pred_ious, matched_gt_inds = self.dynamic_k_matching(cost_matrix, pairwise_ious, num_gt, valid_mask)\n",
    "        \n",
    "        # Convert to AssignResult format: assign matched gt indices, labels and IoU scores\n",
    "        assigned_gt_inds[valid_mask] = matched_gt_inds + 1\n",
    "        assigned_labels = assigned_gt_inds.new_full((num_bboxes, ), -1)\n",
    "        assigned_labels[valid_mask] = gt_labels[matched_gt_inds].long()\n",
    "        max_overlaps = assigned_gt_inds.new_full((num_bboxes, ), -HIGH_COST_VALUE, dtype=torch.float32)\n",
    "        max_overlaps[valid_mask] = matched_pred_ious\n",
    "                    \n",
    "        return AssignResult(num_gt, assigned_gt_inds, max_overlaps, category_labels=assigned_labels)\n",
    "\n",
    "    def get_in_gt_and_in_center_info(self, \n",
    "                                     output_grid_boxes:torch.Tensor, # All output_grid_boxes of one image, a 2D-Tensor with shape [num_output_grid_boxes, 4] in [cx, xy, stride_w, stride_y] format.\n",
    "                                     gt_bboxes # Ground truth bboxes of one image, a 2D-Tensor with shape [num_gts, 4] in [tl_x, tl_y, br_x, br_y] format.\n",
    "                                    ) -> Tuple[torch.Tensor, torch.Tensor]: # The first tensor indicates if the output_grid_box is in any ground truth box or center, the second tensor specifies if the output_grid_box is in both the ground truth box and center.\n",
    "        \"\"\"Get the information about whether output_grid_boxes are in ground truth boxes or center.\n",
    "        \n",
    "        This method determines which predicted boxes are inside a ground truth box and also at the center of the ground truth box. \n",
    "        It computes the centers of the ground truth boxes, checks if the predicted boxes are inside the ground truth boxes and centers, \n",
    "        and then returns a mask indicating which predicted boxes are in either any ground truth box or any center box and which are in both.\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate the centers of the ground truth boxes\n",
    "        gt_cxs = (gt_bboxes[:, 0] + gt_bboxes[:, 2]) / 2.0\n",
    "        gt_cys = (gt_bboxes[:, 1] + gt_bboxes[:, 3]) / 2.0\n",
    "\n",
    "        # Calculate the boundaries for the ground truth boxes\n",
    "        gt_bounds = torch.stack([\n",
    "            output_grid_boxes[:, 0, None] - gt_bboxes[:, 0], \n",
    "            output_grid_boxes[:, 1, None] - gt_bboxes[:, 1], \n",
    "            gt_bboxes[:, 2] - output_grid_boxes[:, 0, None], \n",
    "            gt_bboxes[:, 3] - output_grid_boxes[:, 1, None]\n",
    "        ], dim=1)\n",
    "\n",
    "        # Check if output_grid_boxes are inside the ground truth boxes\n",
    "        is_in_gts = gt_bounds.min(dim=1).values > 0\n",
    "        is_in_gts_all = is_in_gts.any(dim=1)\n",
    "\n",
    "        # Prepare the boundaries for the center boxes\n",
    "        ct_bounds = torch.stack([\n",
    "            output_grid_boxes[:, 0, None] - (gt_cxs - self.center_radius * output_grid_boxes[:, 2, None]),\n",
    "            output_grid_boxes[:, 1, None] - (gt_cys - self.center_radius * output_grid_boxes[:, 3, None]),\n",
    "            (gt_cxs + self.center_radius * output_grid_boxes[:, 2, None]) - output_grid_boxes[:, 0, None],\n",
    "            (gt_cys + self.center_radius * output_grid_boxes[:, 3, None]) - output_grid_boxes[:, 1, None]\n",
    "        ], dim=1)\n",
    "\n",
    "        # Check if output_grid_boxes are inside the center boxes\n",
    "        is_in_cts = ct_bounds.min(dim=1).values > 0\n",
    "        is_in_cts_all = is_in_cts.any(dim=1)\n",
    "\n",
    "        # Check if output_grid_boxes are in either any ground truth box or any center box\n",
    "        is_in_gts_or_centers = is_in_gts_all | is_in_cts_all\n",
    "\n",
    "        # Check if output_grid_boxes are in both ground truth boxes and centers\n",
    "        is_in_boxes_and_centers = is_in_gts[is_in_gts_or_centers, :] & is_in_cts[is_in_gts_or_centers, :]\n",
    "\n",
    "        return is_in_gts_or_centers, is_in_boxes_and_centers\n",
    "    \n",
    "    def dynamic_k_matching(self, \n",
    "                           cost:torch.Tensor, # A 2D tensor representing the cost matrix calculated from both classification cost and regression IoU cost. Shape is [num_output_grid_boxes, num_gts].\n",
    "                           pairwise_ious:torch.Tensor, # A 2D tensor representing IoU scores between predictions and ground truths. Shape is [num_output_grid_boxes, num_gts].\n",
    "                           num_gt:int, # The number of ground truth boxes.\n",
    "                           valid_mask:torch.Tensor # A 1D tensor representing which predicted boxes are valid based on being in gt bboxes and in centers. Shape is [num_output_grid_boxes].\n",
    "                          ) -> Tuple[torch.Tensor, torch.Tensor]: # (IoU scores for matched pairs, The indices of the ground truth for each output_grid_box)\n",
    "        \"\"\"\n",
    "        This method performs the dynamic k-matching process. \n",
    "        For each ground truth box, it finds the top-k matching box predictions based on the smallest cost. \n",
    "        If a predicted box matches multiple ground truths, it keeps only the one with the smallest cost. \n",
    "        Finally, it returns the matched ground-truth indices and IoUs for valid predicted boxes.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the matching matrix with zeros\n",
    "        matching_matrix = torch.zeros_like(cost)\n",
    "\n",
    "        # Select the top k IoUs for dynamic-k calculation\n",
    "        topk_ious, _ = torch.topk(pairwise_ious, self.candidate_topk, dim=0)\n",
    "\n",
    "        # Calculate dynamic k for each ground truth\n",
    "        dynamic_ks = topk_ious.sum(0).int().clamp(min=1)\n",
    "\n",
    "        # For each ground truth, find top k matching output_grid_boxes based on smallest cost\n",
    "        _, pos_idx = cost.topk(k=dynamic_ks.max().item(), dim=0, largest=False)\n",
    "        for gt_idx in range(num_gt):\n",
    "            matching_matrix[pos_idx[:dynamic_ks[gt_idx], gt_idx], gt_idx] = 1\n",
    "\n",
    "        # If a output_grid_box matches multiple ground truths, keep only the one with smallest cost\n",
    "        output_grid_box_match_gt_mask = matching_matrix.sum(1) > 1\n",
    "        if output_grid_box_match_gt_mask.any():\n",
    "            _, cost_argmin = cost[output_grid_box_match_gt_mask].min(dim=1)\n",
    "            matching_matrix[output_grid_box_match_gt_mask].zero_()\n",
    "            matching_matrix[output_grid_box_match_gt_mask, cost_argmin] = 1\n",
    "\n",
    "        # Update the valid mask based on final matches\n",
    "        valid_mask[valid_mask.clone()] = matching_matrix.sum(1) > 0\n",
    "\n",
    "        # Get the final matched ground truth indices and IoUs for valid predicted boxes\n",
    "        fg_mask_inboxes = matching_matrix.sum(1) > 0\n",
    "        matched_gt_inds = matching_matrix[fg_mask_inboxes].argmax(1)\n",
    "        matched_pred_ious = (matching_matrix * pairwise_ious).sum(1)[fg_mask_inboxes]\n",
    "\n",
    "        return matched_pred_ious, matched_gt_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/cj-mills/cjm-yolox-pytorch/blob/main/cjm_yolox_pytorch/simota.py#L60){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimOTAAssigner.assign\n",
       "\n",
       ">      SimOTAAssigner.assign (pred_scores:torch.Tensor,\n",
       ">                             output_grid_boxes:torch.Tensor,\n",
       ">                             decoded_bboxes:torch.Tensor,\n",
       ">                             gt_bboxes:torch.Tensor, gt_labels:torch.Tensor,\n",
       ">                             gt_bboxes_ignore:Optional[torch.Tensor]=None,\n",
       ">                             eps:float=1e-07)\n",
       "\n",
       "*Assign ground truth to output_grid_boxes using SimOTA.\n",
       "\n",
       "This method assigns predicted bounding boxes to ground truth boxes based on the computed cost matrix. \n",
       "It first extracts valid box predictions and scores. \n",
       "It then calculates the total cost matrix using IoU and classification costs. \n",
       "Finally, it uses the cost matrix to assign each prediction to a ground truth box.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| pred_scores | Tensor |  | Classification scores of each output grid box across all classes. |\n",
       "| output_grid_boxes | Tensor |  | Output grid bounding boxes of one image in format [cx, xy, stride_w, stride_y]. |\n",
       "| decoded_bboxes | Tensor |  | Predicted bounding boxes of one image in format [tl_x, tl_y, br_x, br_y]. |\n",
       "| gt_bboxes | Tensor |  | Ground truth bounding boxes of one image in format [tl_x, tl_y, br_x, br_y]. |\n",
       "| gt_labels | Tensor |  | Ground truth labels of one image, It is a Tensor with shape [num_gts]. |\n",
       "| gt_bboxes_ignore | Optional | None | Ground truth bounding boxes that are labelled as `ignored`, e.g., crowd boxes in COCO. |\n",
       "| eps | float | 1e-07 | A value added to the denominator for numerical stability. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/cj-mills/cjm-yolox-pytorch/blob/main/cjm_yolox_pytorch/simota.py#L60){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimOTAAssigner.assign\n",
       "\n",
       ">      SimOTAAssigner.assign (pred_scores:torch.Tensor,\n",
       ">                             output_grid_boxes:torch.Tensor,\n",
       ">                             decoded_bboxes:torch.Tensor,\n",
       ">                             gt_bboxes:torch.Tensor, gt_labels:torch.Tensor,\n",
       ">                             gt_bboxes_ignore:Optional[torch.Tensor]=None,\n",
       ">                             eps:float=1e-07)\n",
       "\n",
       "*Assign ground truth to output_grid_boxes using SimOTA.\n",
       "\n",
       "This method assigns predicted bounding boxes to ground truth boxes based on the computed cost matrix. \n",
       "It first extracts valid box predictions and scores. \n",
       "It then calculates the total cost matrix using IoU and classification costs. \n",
       "Finally, it uses the cost matrix to assign each prediction to a ground truth box.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| pred_scores | Tensor |  | Classification scores of each output grid box across all classes. |\n",
       "| output_grid_boxes | Tensor |  | Output grid bounding boxes of one image in format [cx, xy, stride_w, stride_y]. |\n",
       "| decoded_bboxes | Tensor |  | Predicted bounding boxes of one image in format [tl_x, tl_y, br_x, br_y]. |\n",
       "| gt_bboxes | Tensor |  | Ground truth bounding boxes of one image in format [tl_x, tl_y, br_x, br_y]. |\n",
       "| gt_labels | Tensor |  | Ground truth labels of one image, It is a Tensor with shape [num_gts]. |\n",
       "| gt_bboxes_ignore | Optional | None | Ground truth bounding boxes that are labelled as `ignored`, e.g., crowd boxes in COCO. |\n",
       "| eps | float | 1e-07 | A value added to the denominator for numerical stability. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SimOTAAssigner.assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/cj-mills/cjm-yolox-pytorch/blob/main/cjm_yolox_pytorch/simota.py#L130){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimOTAAssigner.get_in_gt_and_in_center_info\n",
       "\n",
       ">      SimOTAAssigner.get_in_gt_and_in_center_info\n",
       ">                                                   (output_grid_boxes:torch.Ten\n",
       ">                                                   sor, gt_bboxes)\n",
       "\n",
       "*Get the information about whether output_grid_boxes are in ground truth boxes or center.\n",
       "\n",
       "This method determines which predicted boxes are inside a ground truth box and also at the center of the ground truth box. \n",
       "It computes the centers of the ground truth boxes, checks if the predicted boxes are inside the ground truth boxes and centers, \n",
       "and then returns a mask indicating which predicted boxes are in either any ground truth box or any center box and which are in both.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| output_grid_boxes | Tensor | All output_grid_boxes of one image, a 2D-Tensor with shape [num_output_grid_boxes, 4] in [cx, xy, stride_w, stride_y] format. |\n",
       "| gt_bboxes |  | Ground truth bboxes of one image, a 2D-Tensor with shape [num_gts, 4] in [tl_x, tl_y, br_x, br_y] format. |\n",
       "| **Returns** | **Tuple** | **The first tensor indicates if the output_grid_box is in any ground truth box or center, the second tensor specifies if the output_grid_box is in both the ground truth box and center.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/cj-mills/cjm-yolox-pytorch/blob/main/cjm_yolox_pytorch/simota.py#L130){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimOTAAssigner.get_in_gt_and_in_center_info\n",
       "\n",
       ">      SimOTAAssigner.get_in_gt_and_in_center_info\n",
       ">                                                   (output_grid_boxes:torch.Ten\n",
       ">                                                   sor, gt_bboxes)\n",
       "\n",
       "*Get the information about whether output_grid_boxes are in ground truth boxes or center.\n",
       "\n",
       "This method determines which predicted boxes are inside a ground truth box and also at the center of the ground truth box. \n",
       "It computes the centers of the ground truth boxes, checks if the predicted boxes are inside the ground truth boxes and centers, \n",
       "and then returns a mask indicating which predicted boxes are in either any ground truth box or any center box and which are in both.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| output_grid_boxes | Tensor | All output_grid_boxes of one image, a 2D-Tensor with shape [num_output_grid_boxes, 4] in [cx, xy, stride_w, stride_y] format. |\n",
       "| gt_bboxes |  | Ground truth bboxes of one image, a 2D-Tensor with shape [num_gts, 4] in [tl_x, tl_y, br_x, br_y] format. |\n",
       "| **Returns** | **Tuple** | **The first tensor indicates if the output_grid_box is in any ground truth box or center, the second tensor specifies if the output_grid_box is in both the ground truth box and center.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SimOTAAssigner.get_in_gt_and_in_center_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/cj-mills/cjm-yolox-pytorch/blob/main/cjm_yolox_pytorch/simota.py#L177){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimOTAAssigner.dynamic_k_matching\n",
       "\n",
       ">      SimOTAAssigner.dynamic_k_matching (cost:torch.Tensor,\n",
       ">                                         pairwise_ious:torch.Tensor,\n",
       ">                                         num_gt:int, valid_mask:torch.Tensor)\n",
       "\n",
       "*This method performs the dynamic k-matching process. \n",
       "For each ground truth box, it finds the top-k matching box predictions based on the smallest cost. \n",
       "If a predicted box matches multiple ground truths, it keeps only the one with the smallest cost. \n",
       "Finally, it returns the matched ground-truth indices and IoUs for valid predicted boxes.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| cost | Tensor | A 2D tensor representing the cost matrix calculated from both classification cost and regression IoU cost. Shape is [num_output_grid_boxes, num_gts]. |\n",
       "| pairwise_ious | Tensor | A 2D tensor representing IoU scores between predictions and ground truths. Shape is [num_output_grid_boxes, num_gts]. |\n",
       "| num_gt | int | The number of ground truth boxes. |\n",
       "| valid_mask | Tensor | A 1D tensor representing which predicted boxes are valid based on being in gt bboxes and in centers. Shape is [num_output_grid_boxes]. |\n",
       "| **Returns** | **Tuple** | **(IoU scores for matched pairs, The indices of the ground truth for each output_grid_box)** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/cj-mills/cjm-yolox-pytorch/blob/main/cjm_yolox_pytorch/simota.py#L177){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimOTAAssigner.dynamic_k_matching\n",
       "\n",
       ">      SimOTAAssigner.dynamic_k_matching (cost:torch.Tensor,\n",
       ">                                         pairwise_ious:torch.Tensor,\n",
       ">                                         num_gt:int, valid_mask:torch.Tensor)\n",
       "\n",
       "*This method performs the dynamic k-matching process. \n",
       "For each ground truth box, it finds the top-k matching box predictions based on the smallest cost. \n",
       "If a predicted box matches multiple ground truths, it keeps only the one with the smallest cost. \n",
       "Finally, it returns the matched ground-truth indices and IoUs for valid predicted boxes.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| cost | Tensor | A 2D tensor representing the cost matrix calculated from both classification cost and regression IoU cost. Shape is [num_output_grid_boxes, num_gts]. |\n",
       "| pairwise_ious | Tensor | A 2D tensor representing IoU scores between predictions and ground truths. Shape is [num_output_grid_boxes, num_gts]. |\n",
       "| num_gt | int | The number of ground truth boxes. |\n",
       "| valid_mask | Tensor | A 1D tensor representing which predicted boxes are valid based on being in gt bboxes and in centers. Shape is [num_output_grid_boxes]. |\n",
       "| **Returns** | **Tuple** | **(IoU scores for matched pairs, The indices of the ground truth for each output_grid_box)** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SimOTAAssigner.dynamic_k_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
